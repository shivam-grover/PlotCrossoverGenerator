{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PlotGenerator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitadd/StyleTransfer_CrossoverGenerator/blob/master/PlotGenerator_withfeaturecount.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mo3t_TPnHW-i",
        "colab_type": "code",
        "outputId": "68dace9a-8d51-4038-d67c-af28c0f857c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/harshitadd/gpt-2.git\n",
        "import os \n",
        "os.chdir('gpt-2')\n",
        "!sh download_model.sh 117M \n",
        "!pip3 install -r requirements.txt\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'gpt-2' already exists and is not an empty directory.\n",
            "Fetching 117M/checkpoint\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    77  100    77    0     0    606      0 --:--:-- --:--:-- --:--:--   606\n",
            "Fetching 117M/encoder.json\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1017k  100 1017k    0     0  38.2M      0 --:--:-- --:--:-- --:--:-- 38.2M\n",
            "Fetching 117M/hparams.json\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    90  100    90    0     0    873      0 --:--:-- --:--:-- --:--:--   873\n",
            "Fetching 117M/model.ckpt.data-00000-of-00001\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  474M  100  474M    0     0   167M      0  0:00:02  0:00:02 --:--:--  167M\n",
            "Fetching 117M/model.ckpt.index\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5215  100  5215    0     0   282k      0 --:--:-- --:--:-- --:--:--  299k\n",
            "Fetching 117M/model.ckpt.meta\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  460k  100  460k    0     0  19.5M      0 --:--:-- --:--:-- --:--:-- 19.5M\n",
            "Fetching 117M/vocab.bpe\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  445k  100  445k    0     0  19.7M      0 --:--:-- --:--:-- --:--:-- 19.7M\n",
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.1.3)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WYL6P_lRItkp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "outputId": "90c8e5f3-01a4-4595-c988-2c24acdf38f5"
      },
      "cell_type": "code",
      "source": [
        "!python3 src/interactive_conditional_samples.py --top_k 40 --temperature 0.8 --length 250\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-03-08 03:11:59.907513: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-03-08 03:11:59.907792: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x227a680 executing computations on platform Host. Devices:\n",
            "2019-03-08 03:11:59.907836: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-03-08 03:11:59.976798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-03-08 03:11:59.977370: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2279fa0 executing computations on platform CUDA. Devices:\n",
            "2019-03-08 03:11:59.977414: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-03-08 03:11:59.977838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 9.96GiB\n",
            "2019-03-08 03:11:59.977926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-03-08 03:12:00.414476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-03-08 03:12:00.414557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-03-08 03:12:00.414595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-03-08 03:12:00.414933: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-03-08 03:12:00.415006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9646 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /content/gpt-2/gpt-2/src/sample.py:51: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/gpt-2/src/sample.py:53: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.random.categorical instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Model prompt >>> jack a poor farmer was walking home one stormy night and jill a young girl was swimmming in the clear stream in broad daylight.\n",
            "2019-03-08 03:12:22.163399: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "======================================== SAMPLE 1 ========================================\n",
            " One rainy night, the old lady, who was the keeper of the house, saw the old lady, and she was amazed to see her little girl's eyes on the bank of a river. It is a beautiful picture of a little girl who has always spent a good night in a dream.\n",
            "\n",
            "To understand how this story was told is not enough to understand the events. The story is very simple. A woman, about the age of fifteen, was brought up by her father. She was raised by her uncle, who had been an artist. When her uncle died, his widow, who was a member of the church, and children were brought up in her, she left her uncle's family. She went to school with her uncle. The girl came back to her family with a very good education and her family was very happy. She was very happy. Later on she was sent to the school school. The school was crowded with pupils, it was hot and wet, and the girls all had to look for water.\n",
            "\n",
            "When the school year was over, the school-girl was given a very good education. Her uncle was a poor man, and he had a large house, and he had a lot of money and he\n",
            "================================================================================\n",
            "Model prompt >>> Jack a poor farmer was walking home one stormy night and Jill a young girl was swimming in the clear stream in broad daylight.\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "The girl's mother was standing in the open water on the edge of the stream and a few miles away, on the edge of the stream. The girl's father was standing on the edge of the stream and Jill was standing on the edge of the stream, too. The father had been on the edge of the stream with his little girl named K.\n",
            "\n",
            "\"You see, she was swimming in the stream,\" said the father. \"She was swimming at full speed. She was swimming in the muddy water, and she couldn't see us because my son was there. So she's swimming in the muddy water and she's swimming in the mud. That's what we called the muddy water. We had to make sure she was swimming in the muddy water and she didn't see us.\"\n",
            "\n",
            "At the time, the first day of school was a day off from home so Jill had to go to the school and teach with the rest of the kids.\n",
            "\n",
            "\"It was a very difficult day, but I guess I don't regret it,\" said Jill. \"There are always problems. The first day, we didn't have any homework. It was a very challenging day. That's why I put up a sign\n",
            "================================================================================\n",
            "Model prompt >>> "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k2nKl5DsNCVo",
        "colab_type": "code",
        "outputId": "fa466557-339e-4865-da12-2a3a3e44cb2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1515
        }
      },
      "cell_type": "code",
      "source": [
        "!python3 src/interactive_conditional_samples.py --top_k 20 --temperature 6 --length 200\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-03-08 03:07:18.411988: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-03-08 03:07:18.412295: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1a7c680 executing computations on platform Host. Devices:\n",
            "2019-03-08 03:07:18.412338: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-03-08 03:07:18.479710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-03-08 03:07:18.480317: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1a7bfa0 executing computations on platform CUDA. Devices:\n",
            "2019-03-08 03:07:18.480359: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-03-08 03:07:18.480746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 9.96GiB\n",
            "2019-03-08 03:07:18.480783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-03-08 03:07:18.884670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-03-08 03:07:18.884756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-03-08 03:07:18.884778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-03-08 03:07:18.885070: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-03-08 03:07:18.885161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9646 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 5253, in get_controller\n",
            "    yield g\n",
            "  File \"src/interactive_conditional_samples.py\", line 42, in interact_model\n",
            "    temperature=temperature, top_k=top_k\n",
            "  File \"/content/gpt-2/src/sample.py\", line 76, in sample_sequence\n",
            "    back_prop=False,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3556, in while_loop\n",
            "    return_same_structure)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3087, in BuildLoop\n",
            "    pred, body, original_loop_vars, loop_vars, shape_invariants)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3022, in _BuildLoop\n",
            "    body_result = body(*packed_vars_for_body)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3525, in <lambda>\n",
            "    body = lambda i, lv: (i + 1, orig_body(*lv))\n",
            "  File \"/content/gpt-2/src/sample.py\", line 50, in body\n",
            "    next_outputs = step(hparams, prev[:, tf.newaxis], past=past)\n",
            "  File \"/content/gpt-2/src/sample.py\", line 33, in step\n",
            "    lm_output = model.model(hparams=hparams, X=tokens, past=past, reuse=tf.AUTO_REUSE)\n",
            "  File \"/content/gpt-2/src/model.py\", line 164, in model\n",
            "    h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n",
            "  File \"/content/gpt-2/src/model.py\", line 126, in block\n",
            "    a, present = attn(norm(x, 'ln_1'), 'attn', nx, past=past, hparams=hparams)\n",
            "  File \"/content/gpt-2/src/model.py\", line 103, in attn\n",
            "    q, k, v = map(split_heads, tf.split(c, 3, axis=2))\n",
            "  File \"/content/gpt-2/src/model.py\", line 77, in split_heads\n",
            "    return tf.transpose(split_states(x, hparams.n_head), [0, 2, 1, 3])\n",
            "  File \"/content/gpt-2/src/model.py\", line 43, in split_states\n",
            "    return tf.reshape(x, start + [n, m//n])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 7179, in reshape\n",
            "    \"Reshape\", tensor=tensor, shape=shape, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1835, in __init__\n",
            "    self._graph._add_op(self)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2965, in _add_op\n",
            "    if op.name in self._nodes_by_name:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1930, in name\n",
            "    return c_api.TF_OperationName(self._c_op)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 68, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 127, in Fire\n",
            "    component_trace = _Fire(component, args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 366, in _Fire\n",
            "    component, remaining_args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 542, in _CallCallable\n",
            "    result = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 65, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1592, in __exit__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 728, in close\n",
            "    tf_session.TF_CloseSession(self._session)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}